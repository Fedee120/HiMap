{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility\n",
    "\n",
    "from pymilvus import connections\n",
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  host='localhost',\n",
    "  port='19530'\n",
    ")\n",
    "\n",
    "# 2. Define fields\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"filename\", dtype=DataType.VARCHAR, max_length=128), \n",
    "    FieldSchema(name=\"sentence\", dtype=DataType.VARCHAR, max_length=4096), \n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "]\n",
    "\n",
    "# 3. Build the schema\n",
    "schema = CollectionSchema(\n",
    "    fields,\n",
    "    description=\"Schema of docs v2\",\n",
    "        enable_dynamic_field=False\n",
    ")\n",
    "\n",
    "# 4. Create collection\n",
    "collection = Collection(\n",
    "    name=\"python_docV2\", \n",
    "    description=\"Python documentation collection V2\",\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# 5. Create index\n",
    "\n",
    "index_params = {\n",
    "    \"index_type\": \"AUTOINDEX\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "# To name the index, do as follows:\n",
    "collection.create_index(\n",
    "  field_name=\"embedding\", \n",
    "  index_params=index_params,\n",
    "  index_name='embedding_index'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_docs_to_db(batch_data):\n",
    "    res = collection.insert(\n",
    "        data=batch_data\n",
    "    )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"processed_data.json\"\n",
    "data = load_json(json_file_path)\n",
    "\n",
    "# Insert data to the database\n",
    "insert_result = insert_docs_to_db(data)\n",
    "print(f\"Insert result: {insert_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection, utility\n",
    "utility.drop_collection(\"python_docV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = \"processed_data.json\"\n",
    "data = load_json(json_file_path)\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence: contents of limited api currently the limited api includes the following items pyaitercheck pyargparse pyargparsetuple pyargparsetupleandkeywords pyargunpacktuple pyargvaparse pyargvaparsetupleandkeywords pyargvalidatekeywordarguments pybaseobjecttype pyboolfromlong pybooltype pybufferfillcontiguousstrides pybufferfillinfo pybufferfromcontiguous pybuffergetpointer pybufferiscontiguous pybufferrelease pybuffersizefromformat pybuffertocontiguous pybytearrayitertype pybytearrayasstring pybytearrayconcat pybytearrayfromobject pybytearrayfromstringandsize pybytearrayresize pybytearraysize pybytearraytype pybytesitertype pybytesasstring pybytesasstringandsize pybytesconcat pybytesconcatanddel pybytesdecodeescape pybytesfromformat pybytesfromformatv pybytesfromobject pybytesfromstring pybytesfromstringandsize pybytesrepr pybytessize pybytestype pycfunction pycfunctionwithkeywords pycfunctioncall pycfunctiongetflags pycfunctiongetfunction pycfunctiongetself pycfunctionnew pycfunctionnewex pycfunctiontype pycmethodnew pycalliternew pycallitertype pycallablecheck pycapsuledestructor pycapsulegetcontext pycapsulegetdestructor pycapsulegetname pycapsulegetpointer pycapsuleimport pycapsuleisvalid pycapsulenew pycapsulesetcontext pycapsulesetdestructor pycapsulesetname pycapsulesetpointer pycapsuletype pyclassmethoddescrtype pycodecbackslashreplaceerrors pycodecdecode pycodecdecoder pycodecencode pycodecencoder pycodecignoreerrors pycodecincrementaldecoder pycodecincrementalencoder pycodecknownencoding pycodeclookuperror pycodecnamereplaceerrors pycodecregister pycodecregistererror pycodecreplaceerrors pycodecstreamreader pycodecstreamwriter pycodecstricterrors pycodecunregister pycodecxmlcharrefreplaceerrors pycomplexfromdoubles pycompleximagasdouble pycomplexrealasdouble pycomplextype pydescrnewclassmethod pydescrnewgetset pydescrnewmember pydescrnewmethod pydictitemstype pydictiteritemtype pydictiterkeytype pydictitervaluetype pydictkeystype pydictproxynew pydictproxytype pydictreviteritemtype pydictreviterkeytype pydictrevitervaluetype pydictvaluestype pydictclear pydictcontains pydictcopy pydictdelitem pydictdelitemstring pydictgetitem pydictgetitemstring pydictgetitemwitherror pydictitems pydictkeys pydictmerge pydictmergefromseq2 pydictnew pydictnext pydictsetitem pydictsetitemstring pydictsize pydicttype pydictupdate pydictvalues pyellipsistype pyenumtype pyerrbadargument pyerrbadinternalcall pyerrchecksignals pyerrclear pyerrdisplay pyerrexceptionmatches pyerrfetch pyerrformat pyerrformatv pyerrgetexcinfo pyerrgethandledexception pyerrgivenexceptionmatches pyerrnewexception pyerrnewexceptionwithdoc pyerrnomemory pyerrnormalizeexception pyerroccurred pyerrprint pyerrprintex pyerrprogramtext pyerrresourcewarning pyerrrestore pyerrsetexcfromwindowserr pyerrsetexcfromwindowserrwithfilename pyerrsetexcfromwindowserrwithfilenameobject pyerrsetexcfromwindowserrwithfilenameobjects pyerrsetexcinfo pyerrsetfromerrno pyerrsetfromerrnowithfilename pyerrsetfromerrnowithfilenameobject pyerrsetfromerrnowithfilenameobjects pyerrsetfromwindowserr pyerrsetfromwindowserrwithfilename pyerrsethandledexception pyerrsetimporterror pyerrsetimporterrorsubclass pyerrsetinterrupt pyerrsetinterruptex pyerrsetnone pyerrsetobject pyerrsetstring pyerrsyntaxlocation pyerrsyntaxlocationex pyerrwarnex pyerrwarnexplicit pyerrwarnformat pyerrwriteunraisable pyevalacquirelock pyevalacquirethread pyevalcallfunction pyevalcallmethod pyevalcallobjectwithkeywords pyevalevalcode pyevalevalcodeex pyevalevalframe pyevalevalframeex pyevalgetbuiltins pyevalgetframe pyevalgetfuncdesc pyevalgetfuncname pyevalgetglobals pyevalgetlocals pyevalinitthreads pyevalreleaselock pyevalreleasethread pyevalrestorethread pyevalsavethread pyevalthreadsinitialized pyexcarithmeticerror pyexcassertionerror pyexcattributeerror pyexcbaseexception pyexcbaseexceptiongroup pyexcblockingioerror pyexcbrokenpipeerror pyexcbuffererror pyexcbyteswarning pyexcchildprocesserror pyexcconnectionabortederror pyexcconnectionerror pyexcconnectionrefusederror pyexcconnectionreseterror pyexcdeprecationwarning pyexceoferror pyexcencodingwarning pyexcenvironmenterror pyexcexception pyexcfileexistserror pyexcfilenotfounderror pyexcfloatingpointerror pyexcfuturewarning pyexcgeneratorexit pyexcioerror pyexcimporterror pyexcimportwarning pyexcindentationerror pyexcindexerror pyexcinterruptederror pyexcisadirectoryerror pyexckeyerror pyexckeyboardinterrupt pyexclookuperror pyexcmemoryerror pyexcmodulenotfounderror pyexcnameerror pyexcnotadirectoryerror pyexcnotimplementederror pyexcoserror pyexcoverflowerror pyexcpendingdeprecationwarning pyexcpermissionerror pyexcprocesslookuperror pyexcrecursionerror pyexcreferenceerror pyexcresourcewarning pyexcruntimeerror\n"
     ]
    }
   ],
   "source": [
    "# Find the longest sentence\n",
    "longest_sentence = \"\"\n",
    "for record in data:\n",
    "    if len(record['sentence']) > len(longest_sentence):\n",
    "        longest_sentence = record['sentence']\n",
    "\n",
    "print(f\"Longest sentence: {longest_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of entries: 90167\n",
      "Number of entries after filtering: 90151\n",
      "Entries removed: 16\n"
     ]
    }
   ],
   "source": [
    "filtered_data = [record for record in data if len(record['sentence']) <= 2048]\n",
    "\n",
    "print(f\"Original number of entries: {len(data)}\")\n",
    "print(f\"Number of entries after filtering: {len(filtered_data)}\")\n",
    "print(f\"Entries removed: {len(data) - len(filtered_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert result for chunk 1/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857009038327810, success count: 10000, err count: 0)\n",
      "Insert result for chunk 2/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857009339793412, success count: 10000, err count: 0)\n",
      "Insert result for chunk 3/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857009627889666, success count: 10000, err count: 0)\n",
      "Insert result for chunk 4/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857009916248068, success count: 10000, err count: 0)\n",
      "Insert result for chunk 5/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857010204606465, success count: 10000, err count: 0)\n",
      "Insert result for chunk 6/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857010492964868, success count: 10000, err count: 0)\n",
      "Insert result for chunk 7/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857010781323266, success count: 10000, err count: 0)\n",
      "Insert result for chunk 8/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857011069681669, success count: 10000, err count: 0)\n",
      "Insert result for chunk 9/10: (insert count: 10000, delete count: 0, upsert count: 0, timestamp: 443857011358040065, success count: 10000, err count: 0)\n",
      "Insert result for chunk 10/10: (insert count: 151, delete count: 0, upsert count: 0, timestamp: 443857011384516612, success count: 151, err count: 0)\n"
     ]
    }
   ],
   "source": [
    "def insert_docs_to_db(batch_data):\n",
    "    res = collection.insert(\n",
    "        data=batch_data\n",
    "    )\n",
    "    return res\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 10000\n",
    "total_chunks = len(data) // chunk_size + (1 if len(data) % chunk_size else 0)\n",
    "\n",
    "for idx in range(total_chunks):\n",
    "    start_idx = idx * chunk_size\n",
    "    end_idx = (idx + 1) * chunk_size\n",
    "    chunked_data = data[start_idx:end_idx]\n",
    "    \n",
    "    # Insert each chunk to the database\n",
    "    insert_result = insert_docs_to_db(chunked_data)\n",
    "    print(f\"Insert result for chunk {idx+1}/{total_chunks}: {insert_result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
