{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize DistilBERT tokenizer and model\n",
    "#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "#model = SentenceTransformer('sentence-transformers/sentence-t5-base')\n",
    "#model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "def get_embedding(chunk):\n",
    "    \"\"\"Get the embedding vector for a chunk of text\"\"\"\n",
    "    return model.encode(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility, db\n",
    "\n",
    "from pymilvus import connections\n",
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  host='localhost',\n",
    "  port='19530'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import Collection\n",
    "collection = Collection(\"python_doc\")      # Get an existing collection.\n",
    "collection.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    \"metric_type\": \"L2\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to search:  3.999948501586914 ms\n",
      "[\"['id: 3141, distance: 0.3555751442909241, entity: {}', 'id: 3160, distance: 0.3647070527076721, entity: {}', 'id: 3041, distance: 0.5579851865768433, entity: {}', 'id: 3475, distance: 0.6107275485992432, entity: {}', 'id: 3052, distance: 0.699018657207489, entity: {}', 'id: 31886, distance: 0.7414852380752563, entity: {}', 'id: 58368, distance: 0.7472877502441406, entity: {}', 'id: 3268, distance: 0.7857130765914917, entity: {}', 'id: 3043, distance: 0.8134196400642395, entity: {}', 'id: 31389, distance: 0.8148602247238159, entity: {}']\"]\n"
     ]
    }
   ],
   "source": [
    "#query_vector = get_embedding(\"how do i write a module in C or C++?\")\n",
    "query_vector = get_embedding(\"how do i use regular expressions in Python?\")\n",
    "#time the search\n",
    "import time\n",
    "start = time.time()\n",
    "res = collection.search(\n",
    "    data=[query_vector],\n",
    "    anns_field=\"embedding\",\n",
    "    param=search_params,\n",
    "    limit=10,\n",
    ")\n",
    "end = time.time()\n",
    "#print the time in ms\n",
    "print(\"Time to search: \", (end - start)*1000, \"ms\")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3141, 3160, 3041, 3475, 3052, 31886, 58368, 3268, 3043, 31389]\n"
     ]
    }
   ],
   "source": [
    "#append to a list the ids of the response considering the structure is[\"['id: 4917, distance: 0.6798818111419678, entity: {}', 'id: 10402, distance: 0.6981911659240723, entity: {}', 'id: 2335, distance: 0.707775354385376, entity: {}', 'id: 9312, distance: 0.7683041095733643, entity: {}', 'id: 9599, distance: 0.7878801822662354, entity: {}', 'id: 4622, distance: 0.8129417896270752, entity: {}', 'id: 2336, distance: 0.8555702567100525, entity: {}', 'id: 10408, distance: 0.8695672750473022, entity: {}', 'id: 11102, distance: 0.8719511032104492, entity: {}', 'id: 10665, distance: 0.8743786215782166, entity: {}']\"]\n",
    "#then we can use the ids to get the text from the files\n",
    "ids = res[0].ids\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Regular Expression HOWTO\n",
      "************************\n",
      "\n",
      "Author:\n",
      "   A.M. Kuchling <amk@amk.ca>\n",
      "\n",
      "\n",
      "Abstract\n",
      "^^^^^^^^\n",
      "\n",
      "This document is an introductory tutorial to using regular expressions\n",
      "in Python with the \"re\" module.\n",
      "2. Introduction\n",
      "============\n",
      "\n",
      "Regular expressions (called REs, or regexes, or regex patterns) are\n",
      "essentially a tiny, highly specialized programming language embedded\n",
      "inside Python and made available through the \"re\" module.\n",
      "3. In\n",
      "these cases, you may be better off writing Python code to do the\n",
      "processing; while Python code will be slower than an elaborate regular\n",
      "expression, it will also probably be more understandable.\n",
      "4. Using Regular Expressions\n",
      "=========================\n",
      "\n",
      "Now that we've looked at some simple regular expressions, how do we\n",
      "actually use them in Python?\n",
      "5. Regular expressions will often be written\n",
      "in Python code using this raw string notation.\n",
      "6. First, this is the worst collision between\n",
      "   Python's string literals and regular expression sequences.\n",
      "7. (The first edition covered Python's now-removed \"regex\" module, which\n",
      "won't help you much.)\n",
      "8. Regular expressions can contain both special and ordinary characters.\n",
      "9. Mastering Regular Expressions.\n",
      "10. Python 2.4's regular expression engine can match this\n",
      "  pattern without problems.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def retrieve_sentences_from_ids(ids):\n",
    "    # Load data from JSON file\n",
    "    with open(\"sentence_data.json\", 'r', encoding='utf-8') as json_file:\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    # Filter sentences with the given IDs\n",
    "    retrieved_sentences = [record['sentence'] for record in data if record['id'] in ids]\n",
    "\n",
    "    # Print retrieved sentences\n",
    "    for idx, sentence in enumerate(retrieved_sentences, 1):\n",
    "        print(f\"{idx}. {sentence}\")\n",
    "\n",
    "\n",
    "retrieve_sentences_from_ids(ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in collection:  90167\n",
      "Is empty:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of elements in collection: \", collection.num_entities)\n",
    "print(\"Is empty: \", collection.is_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
